OPEN SOURCE • AMBIENT EMAIL AGENT
PROJECT: LangGraph Email Assistant with a Web Frontend CLIENT: Kbediako Bedaiko
SOLUTIONS ARCHITECT: Makomo Chimba DATE: NULL

Architecture Overview:

To integrate a web UI with the LangGraph-based Email Assistant, we will introduce a client–server architecture. The backend (Python) will host the LangGraph email assistant (using Google’s Gemini API for LLM calls) and expose a web API (e.g. via Flask or FastAPI) for the frontend. A SQL database (e.g. SQLite or Postgres) persists emails, draft replies, and pending actions so that agent state and user decisions survive restarts. The frontend (e.g. a React single-page app) will allow the user to view incoming emails, inspect or edit AI-drafted replies, and approve/modify any tool actions before they execute. This human-in-the-loop design leverages LangGraph’s built-in interrupt mechanism (the HumanInterrupt agent inbox) to pause agent execution for user input. Below we detail each component and feature.

In summary, the plan is to use a Flask (or FastAPI) backend to run the LangGraph email assistant and store its state, and a React frontend to present an Inbox of incoming emails, an Email Draft Review screen for editing/approving replies, and interactive Approval Prompts for any tool actions (meetings, reminders, etc.) that the assistant proposes. This harnesses LangGraph’s human-in-the-loop interrupts – by pausing the agent at critical points – and gives the human controller final say before any external effect (sending email, scheduling events) is performed. By integrating with the agent’s checkpoint and resume API, we ensure the UI is tightly coupled with the agent’s state machine. This design will allow the assistant to evolve into a production-ready system combining AI automation with human judgment.

Backend: Python Integration with LangGraph and SQL

1. Database Schema: Define SQL tables to store emails and agent action state. For example:
Emails – Fields: id, sender, subject, body, status, etc. The status can be an enum (NEW, PENDING_REPLY, REPLIED, SPAM, etc.) to track what the assistant decided. If the assistant drafts a reply, set status to PENDING_REPLY until user approval.
Drafts – Fields: email_id (FK to Emails), draft_body, draft_subject, created_at. Stores the AI-generated draft reply content for each email that requires approval.
Actions/Approvals – Fields: id, email_id (nullable if action not tied to a single email), action_type (e.g. "send_email", "schedule_meeting", "reminder"), action_params (JSON details of the tool’s arguments), status (PENDING, APPROVED, REJECTED, etc.). This table tracks pending tool executions that need human sign-off (like scheduling a calendar event or creating a reminder).

Using an ORM like SQLAlchemy can simplify model definitions and CRUD operations. For example:

# models.py from sqlalchemy import Column, Integer, String, Text, ForeignKey, JSON, Enum from sqlalchemy.ext.declarative import declarative_base Base = declarative_base()  class Email(Base):     __tablename__ = 'emails'     id = Column(Integer, primary_key=True)     sender = Column(String)     subject = Column(String)     body = Column(Text)     status = Column(String)  # e.g. 'NEW', 'PENDING_REPLY', 'REPLIED', 'SPAM'  class Draft(Base):     __tablename__ = 'drafts'     email_id = Column(Integer, ForeignKey('emails.id'), primary_key=True)     draft_body = Column(Text)     draft_subject = Column(String)

We would also create an EmailActions model for approvals. A SQL migration (using Alembic or Flask-Migrate) can set up these tables.

2. LangGraph Agent Invocation: The backend will incorporate the LangGraph email assistant so it can run on new emails. Whenever a new email arrives (via Gmail API or a webhook), or on demand, we call the LangGraph agent with that email’s content. For instance, if using the email_assistant_hitl_memory_gmail graph (which includes Gmail integration and HITL interrupts), we might do:

from email_assistant import agents  # hypothetical import from the assistant package graph = agents.email_assistant_hitl_memory_gmail  # load the compiled graph # Prepare input for the graph: email_input = {"email": {"from": sender, "subject": subj, "body": body}} thread_config = {"configurable": {"thread_id": gmail_thread_id}} # Run the agent (stream mode to catch interrupts) for event in graph.stream(email_input, thread_config, stream_mode="values"):     handle_event(event)

We use stream() so that we can capture intermediate events, particularly the HumanInterrupt that signals a pause for approval. The agent’s thread ID is set to a unique identifier (e.g. the Gmail thread ID or email ID) so that the agent’s state is check pointed under that key; this allows resuming the same conversation thread later. The LangGraph agent uses a checkpoint saver (backed by SQLite in this case) to persist state at each step. We can configure it to use the same SQL database or a separate SQLite file for agent snapshots. (For example, EMAIL_ASSISTANT_CHECKPOINT_PATH can point to our database file so that SqliteSaver writes to it.)

3. Handling Agent Output and Interrupts: As the agent runs on an email, it will classify and possibly draft a response in its workflow. If the agent decides to auto-handle an email (e.g. mark as spam or no reply needed), it may complete without interruption – we then update the email’s status (e.g. SPAM or IGNORED) and record any final actions. If the agent drafts a reply or needs approval for a tool, it will trigger a HumanInterrupt event. LangGraph’s interrupt() function produces an object (or list of objects) with the action request details for the human. For example, the interrupt might contain:

{   "actionRequest": { "action": "send_email_tool",                       "args": { "to": "<sender>", "body": "<draft content>" } },   "description": "Proposed email reply drafted by assistant.",   "config": { "allowAccept": true, "allowEdit": true, "allowRespond": true } }

On detecting this event, the backend will:
 - Persist the draft: Save the drafted reply content to the Drafts table (and link to the corresponding Email). Mark the Email’s status as PENDING_REPLY. - Persist the action request: Create an entry in the Actions/Approvals table for the pending send_email tool call, including the proposed args (recipient, body, etc.) and set status to PENDING. This represents a task in the “Agent Inbox” that a human needs to review.

If multiple tools require approval (e.g. scheduling a meeting in addition to drafting an email), the agent may interrupt for each in sequence. Each interrupt can be stored similarly. (In practice, the email assistant’s LangGraph is designed to pause before executing sensitive tools like sending email or scheduling, wrapping them in HumanInterrupt calls.) The agent run will effectively pause at the first interrupt.

4. Resume Mechanism: When the user responds via the UI (approves or edits), the backend will resume the paused agent with the user’s input. LangGraph supports resuming by providing a special command object that includes the human’s decision. In Python, this is analogous to sending a resume payload into the graph. For example, to accept the draft as-is:
from langgraph import Command  # hypothetical import resume_cmd = Command({"resume": {"type": "accept"}}) graph.stream(resume_cmd, thread_config)

If the user edited the draft, we send {"resume": {"type": "edit", "args": {<updated fields>}}}. These resume payloads correspond to the options configured in the interrupt (accept, edit, or even a free-form response). Upon resuming, the agent continues execution: e.g. actually sending the email via the Gmail API tool, scheduling the meeting, etc., then finishing the graph. We update the database accordingly (mark email as REPLIED once sent, mark the approval action as APPROVED, etc.).

The human-in-the-loop flow is thus: the agent’s state was saved at interrupt, and after user input, we load that state and continue to completion. (If the user rejects or ignores an action, we can send a resume of type "ignore" to skip that step. and perhaps route the agent to end the flow without executing the tool.)

5. Additional Integrations: The backend can also run a background process to fetch incoming emails and trigger the agent automatically. For instance, a periodic task (Celery beat or a simple loop) could call Gmail API for new messages, insert them into the Emails table (status NEW), and invoke the LangGraph agent for each. The assistant’s reminder system is also handled in backend: when the agent suggests a follow-up reminder, it adds a pending reminder action. The design uses a deferred queue – reminder creations are stored and only applied after the user approves responding. We would surface these in the UI as pending actions (“Reminder: follow up in 3 days?”) and, on approval, resume the agent or run a helper function to apply the reminder (possibly via a worker like the provided reminder_worker.py). The key is that all these side effects (email sends, calendar events) are gated behind an approval step in our backend logic, matching the LangGraph HITL pattern.

Frontend: Web Application (React)
The frontend will be a web application (e.g. built with React and a component library like Material UI) that communicates with the backend API to display emails and pending actions, and to send user decisions. We will implement three main UI features:
Inbox View (Incoming Emails List)

The inbox page will show a table or list of emails that the assistant has processed or is handling. Each entry can display the sender, subject, a snippet of the body, and the assistant’s classification/status. For example, an email could be labeled “Needs Reply” (pending draft approval), “Replied” (already answered by the assistant), “Spam” (auto-flagged), or “Ignored”. This gives the user an overview of what the AI is doing.

Implementation: We’ll create a React component that fetches the list of emails from the backend (e.g. a GET request to /api/emails). The backend returns JSON with email entries (joining the Draft or Actions info as needed). Using React hooks, we fetch on component load and store the data in state:

// InboxView.jsx (simplified) import { useEffect, useState } from 'react';  function InboxView() {   const [emails, setEmails] = useState([]);   useEffect(() => {     fetch('/api/emails')       .then(res => res.json())       .then(data => setEmails(data));   }, []);    return (     <div>       <h2>Inbox</h2>       <table>         <thead><tr><th>Sender</th><th>Subject</th><th>Status</th></tr></thead>         <tbody>           {emails.map(email => (             <tr key={email.id} onClick={() => openEmail(email.id)}>               <td>{email.sender}</td>               <td>{email.subject}</td>               <td>{email.status}</td>             </tr>           ))}         </tbody>       </table>     </div>   ); }

Each row is clickable to open the detailed view for that email. The status field indicates if an email has a pending action. For instance, if status == "PENDING_REPLY", the user knows the assistant drafted a reply awaiting approval. This Inbox UI parallels the concept of an “Agent Inbox” – a list of tasks or notifications from the agent requiring attention. In our case, each email with pending actions appears highlighted. (In a more advanced UI, we could also have a dedicated “Pending Approvals” section listing all action items across emails, similar to LangChain’s Agent Inbox UI which lists tasks requiring human input.)

Draft Review & Editing Interface:

When the user selects an email that has a drafted reply, they are taken to a detail view showing the email thread and the assistant’s proposed response. This page will have a text area (or rich text editor) pre-filled with the AI’s draft so the user can review and optionally edit it. The UI might also show contextual info, e.g., the original email content for reference and any assistant notes (like classification reasoning if available).
Implementation: We create a React component for the email detail. On mount, it fetches the email details and draft content from the backend (e.g. GET /api/emails/{id} returns the email plus associated draft if any). 

The component then renders the original email and an editable text box for the draft reply:

// EmailDetail.jsx function EmailDetail({ emailId }) {   const [email, setEmail] = useState(null);   const [draft, setDraft] = useState("");   useEffect(() => {     fetch(`/api/emails/${emailId}`)       .then(res => res.json())       .then(data => {         setEmail(data.email);         setDraft(data.draft_body || "");       });   }, [emailId]);    const handleDraftChange = e => setDraft(e.target.value);   const handleSubmit = (decision) => {     // POST approval: accept, edit (with new draft), or ignore     const payload = { decision, edited_body: draft };     fetch(`/api/emails/${emailId}/approve`, {       method: 'POST', headers: {'Content-Type': 'application/json'},       body: JSON.stringify(payload)     });   };    if (!email) return <div>Loading...</div>;   return (     <div>       <h3>From: {email.sender}</h3>       <p><b>Subject:</b> {email.subject}</p>       <p>{email.body}</p>       {email.status === "PENDING_REPLY" && (         <div className="draft-section">           <h4>Draft Reply:</h4>           <textarea value={draft} onChange={handleDraftChange} />           <button onClick={() => handleSubmit("accept")}>Send as-is</button>           <button onClick={() => handleSubmit("edit")}>Send with Edits</button>           <button onClick={() => handleSubmit("ignore")}>Discard</button>         </div>       )}     </div>   ); }

In this snippet, we provide three actions: “Send as-is” (accept the AI draft), “Send with Edits” (user modified the draft), and “Discard” (ignore/cancel the reply). These correspond to the types of resume actions defined by the LangGraph HITL schema: Accept, Edit, or Ignore. (We could also include a “Respond” option, where the user gives feedback to the AI to refine the draft without directly editing it – this would map to the response type where the user’s message is used by the agent to rewrite and interrupt again. This is an advanced iterative refinement feature and optional for initial implementation.)

When the user clicks a button, we send a POST to the backend (e.g. /api/emails/123/approve) with their decision. The backend handler will look something like:

@app.route('/api/emails/<int:email_id>/approve', methods=['POST']) def approve_action(email_id):     data = request.get_json()     decision = data.get("decision")  # "accept", "edit", or "ignore"     edited_body = data.get("edited_body")     # Load the stored interrupt/action for this email:     action = db.query(EmailAction).filter_by(email_id=email_id, status="PENDING").first()     if not action:         return {"error": "No pending action"}, 400     # Prepare resume payload for LangGraph     if decision == "accept":         resume_val = {"type": "accept"}     elif decision == "edit":         # update the draft content in args         updated_args = action.action_params  # e.g. {"to": ..., "body": ...}         updated_args["body"] = edited_body         resume_val = {"type": "edit", "args": updated_args}     elif decision == "ignore":         resume_val = {"type": "ignore"}     # Resume the agent execution for this email/thread:     thread_id = action.thread_id  # stored when we first ran the agent     graph.stream(Command({"resume": resume_val}), {"configurable": {"thread_id": thread_id}})     # Update DB status     action.status = "APPROVED" if decision != "ignore" else "REJECTED"     email = db.query(Email).get(email_id)     email.status = "REPLIED" if decision != "ignore" else "IGNORED"     db.commit()     return {"status": "ok"}

In the above pseudo-code, we retrieve the pending action, construct a LangGraph Command to resume the agent, and then update the status. The agent will carry out the tool execution upon resuming (e.g. sending the email via the Gmail API integration, marking the email as read, etc., as defined in the graph). After resumption, our records show the email as replied (or ignored).
Throughout this process, the Gemini LLM API calls are handled inside the LangGraph agent (for drafting content, classifying triage, etc.), so the frontend/backend code doesn’t directly call the LLM – it only triggers the agent. We ensure the GOOGLE_API_KEY and model (e.g. gemini-2.5-pro) are configured in the backend environment so that the agent’s LLM calls succeed.
Approval Prompts for Tool Actions (Meetings, Reminders, etc.)

Beyond email drafting, the assistant can use other tools (calendar scheduling, spam labelling, setting reminders, etc.) We extend the frontend to handle these approval prompts similarly to draft approvals. For instance, if the agent proposes to schedule a meeting via a schedule_meeting_tool, it will interrupt with an actionRequest describing the event details (date, time, participants) and ask for confirmation. Our backend would save this as a pending action (action_type = "schedule_meeting", with args like date/time). In the UI, when the user views that email or a dedicated “Approvals” panel, they should see a prompt: “Schedule a meeting on 2025-10-05 at 3 PM with Alice?” along with Approve, Edit, or Cancel options. An edit might allow adjusting the proposed time or location via form inputs.

Implementation: We can reuse a generic Approval component for such actions. If actions are tied to an email, the Email detail page can list any pending actions (besides the draft). For example:

{pendingActions.map(action => (   action.type === "schedule_meeting" ? (     <div key={action.id} className="approval-box">       <p><b>Meeting Request:</b> {formatDetails(action.params)}</p>       {/* e.g. "Schedule meeting on Oct 5, 3:00 PM with Alice" */}       {/* If editing allowed: show form inputs pre-filled with action.params */}       <button onClick={() => sendApproval(action.id, "accept")}>Approve</button>       <button onClick={() => openEditModal(action)}>Modify</button>       <button onClick={() => sendApproval(action.id, "ignore")}>Decline</button>     </div>   ) : null ))}

Here, pendingActions for the email would include things like meeting proposals or reminder creations. The sendApproval function would POST to an endpoint (say, /api/actions/<id>/approve) with the decision. The backend will then resume the agent or perform the tool call accordingly. In the case of an approved meeting, the agent (upon resume) might call the calendar API tool to actually create the event and then continue the email workflow. For a reminder, the agent’s apply_reminder_actions_node might execute the queued reminder creation once the user has responded to the email..

In essence, each approval prompt in the UI corresponds to a HumanInterrupt that was raised. The UI presents the description and details from the interrupt object (e.g. “Please review the tool call” as generic text, or a custom message). Because the LangGraph interrupt schema is standard, we know the structure: an action name and args, and which responses are allowed. We can render appropriate input fields if the action is editable (for example, allow changing the hotelName in a travel booking scenario, as shown in LangChain’s docs). For simple yes/no approvals, just “Approve” and “Reject” buttons suffice.

Common Libraries: To build these interactive forms and modals, we can leverage component libraries (Material-UI’s Dialog for edit forms, etc.) or form management libraries like Formik for handling edited fields. We also ensure real-time feedback; for instance, once an action is approved, the UI can remove it from the pending list (optimistically or via refetch). Using a state management or SWR/React Query can help keep the UI in sync with the backend.

Notifications and Live Updates (Optional)
For a smoother UX, we can incorporate WebSocket or Server-Sent Events so that the frontend gets notified when new emails arrive or when the agent generates a draft. For example, after the backend processes an email and inserts a Draft, it could emit a WebSocket event. The React app would listen and update the Inbox list (showing a new email with status “Needs Reply”). This real-time aspect aligns with how LangGraph supports streaming events and multi-mode updates. However, a simpler initial approach is to have the user manually refresh or poll the inbox periodically.

Leveraging Existing Tools and Patterns:

We prioritize using LangGraph’s provided capabilities and community tools for human-in-the-loop agents. In fact, LangChain/LangGraph already provide an Agent Inbox UI reference implementation that closely matches our requirements. That open-source Agent Inbox (and the Agent Chat UI) can automatically detect HumanInterrupt schema events and render appropriate UI components for approval. For inspiration or even direct use, we can look at those projects (e.g. the langchain-ai/agent-inbox repository) which implement a web app for reviewing and responding to agent interrupts. 

For instance, the LangChain example “Email Agent” triggers an interrupt with a draft email, and their Agent Chat UI presents Accept/Edit/Respond/Ignore options in a form. Our implementation mirrors this workflow, but tailored to our specific email assistant and using our stack (React/Flask/SQL). We also draw on libraries like gotoHuman (a human approval service) or others for design ideas – these highlight features like an inbox of pending reviews, in-place editing of AI outputs, and webhooks to resume workflows.